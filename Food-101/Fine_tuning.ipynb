{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-06-06T14:09:07.782908Z","iopub.status.busy":"2023-06-06T14:09:07.782320Z","iopub.status.idle":"2023-06-06T14:09:07.791079Z","shell.execute_reply":"2023-06-06T14:09:07.790009Z","shell.execute_reply.started":"2023-06-06T14:09:07.782869Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# # This Python 3 environment comes with many helpful analytics libraries installed\n","# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# # For example, here's several helpful packages to load\n","\n","# import numpy as np # linear algebra\n","# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# # Input data files are available in the read-only \"../input/\" directory\n","# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:09:07.822223Z","iopub.status.busy":"2023-06-06T14:09:07.821938Z","iopub.status.idle":"2023-06-06T14:09:07.837716Z","shell.execute_reply":"2023-06-06T14:09:07.836812Z","shell.execute_reply.started":"2023-06-06T14:09:07.822199Z"},"trusted":true},"outputs":[],"source":["def compare_historys(original_history, new_history, initial_epochs=5):\n","    \"\"\"\n","    Compares two model history objects.\n","    \"\"\"\n","    # Get original history measurements\n","    acc = original_history.history[\"accuracy\"]\n","    loss = original_history.history[\"loss\"]\n","\n","    print(len(acc))\n","\n","    val_acc = original_history.history[\"val_accuracy\"]\n","    val_loss = original_history.history[\"val_loss\"]\n","\n","    # Combine original history with new history\n","    total_acc = acc + new_history.history[\"accuracy\"]\n","    total_loss = loss + new_history.history[\"loss\"]\n","\n","    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n","    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n","\n","    print(len(total_acc))\n","    print(total_acc)\n","\n","    # Make plots\n","    plt.figure(figsize=(8, 8))\n","    plt.subplot(2, 1, 1)\n","    plt.plot(total_acc, label='Training Accuracy')\n","    plt.plot(total_val_acc, label='Validation Accuracy')\n","    plt.plot([initial_epochs-1, initial_epochs-1],\n","              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n","    plt.legend(loc='lower right')\n","    plt.title('Training and Validation Accuracy')\n","\n","    plt.subplot(2, 1, 2)\n","    plt.plot(total_loss, label='Training Loss')\n","    plt.plot(total_val_loss, label='Validation Loss')\n","    plt.plot([initial_epochs-1, initial_epochs-1],\n","              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n","    plt.legend(loc='upper right')\n","    plt.title('Training and Validation Loss')\n","    plt.xlabel('epoch')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:09:07.862102Z","iopub.status.busy":"2023-06-06T14:09:07.861838Z","iopub.status.idle":"2023-06-06T14:09:08.847608Z","shell.execute_reply":"2023-06-06T14:09:08.846476Z","shell.execute_reply.started":"2023-06-06T14:09:07.862078Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Are we using a GPU? (if not & you're using Google Colab, go to Runtime -> Change Runtime Type -> Harware Accelerator: GPU )\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:09:08.850628Z","iopub.status.busy":"2023-06-06T14:09:08.850220Z","iopub.status.idle":"2023-06-06T14:09:20.084390Z","shell.execute_reply":"2023-06-06T14:09:20.083468Z","shell.execute_reply.started":"2023-06-06T14:09:08.850578Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Get helper_functions.py script from course GitHub\n","!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py \n","\n","# Import helper functions we're going to use\n","from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"]},{"cell_type":"markdown","metadata":{},"source":["Wonderful, now we've got a bunch of helper functions we can use throughout the notebook without having to rewrite them from scratch each time.\n","\n","> ðŸ”‘ **Note:** If you're running this notebook in Google Colab, when it times out Colab will delete the `helper_functions.py` file. So to use the functions imported above, you'll have to rerun the cell."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:09:20.086875Z","iopub.status.busy":"2023-06-06T14:09:20.085883Z","iopub.status.idle":"2023-06-06T14:09:23.277450Z","shell.execute_reply":"2023-06-06T14:09:23.276301Z","shell.execute_reply.started":"2023-06-06T14:09:20.086838Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Get 10% of the data of the 10 classes\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip \n","\n","unzip_data(\"10_food_classes_10_percent.zip\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:09:23.281552Z","iopub.status.busy":"2023-06-06T14:09:23.280850Z","iopub.status.idle":"2023-06-06T14:09:23.295067Z","shell.execute_reply":"2023-06-06T14:09:23.294215Z","shell.execute_reply.started":"2023-06-06T14:09:23.281512Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Walk through 10 percent data directory and list number of files\n","walk_through_dir(\"10_food_classes_10_percent\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:09:23.298206Z","iopub.status.busy":"2023-06-06T14:09:23.297941Z","iopub.status.idle":"2023-06-06T14:09:23.303573Z","shell.execute_reply":"2023-06-06T14:09:23.302578Z","shell.execute_reply.started":"2023-06-06T14:09:23.298183Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Create training and test directories\n","train_dir = \"10_food_classes_10_percent/train/\"\n","test_dir = \"10_food_classes_10_percent/test/\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:09:23.305554Z","iopub.status.busy":"2023-06-06T14:09:23.305147Z","iopub.status.idle":"2023-06-06T14:09:26.526304Z","shell.execute_reply":"2023-06-06T14:09:26.525407Z","shell.execute_reply.started":"2023-06-06T14:09:23.305523Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Create data inputs\n","import tensorflow as tf\n","IMG_SIZE = (224, 224) # define image size\n","train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n","                                                                            image_size=IMG_SIZE,\n","                                                                            label_mode=\"categorical\", # what type are the labels?\n","                                                                            batch_size=32) # batch_size is 32 by default, this is generally a good number\n","test_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n","                                                                           image_size=IMG_SIZE,\n","                                                                           label_mode=\"categorical\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:09:26.528176Z","iopub.status.busy":"2023-06-06T14:09:26.527836Z","iopub.status.idle":"2023-06-06T14:09:26.540332Z","shell.execute_reply":"2023-06-06T14:09:26.539377Z","shell.execute_reply.started":"2023-06-06T14:09:26.528144Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Check the training data datatype\n","train_data_10_percent"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:09:26.543828Z","iopub.status.busy":"2023-06-06T14:09:26.543555Z","iopub.status.idle":"2023-06-06T14:09:26.564840Z","shell.execute_reply":"2023-06-06T14:09:26.563906Z","shell.execute_reply.started":"2023-06-06T14:09:26.543805Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Check out the class names of our dataset\n","train_data_10_percent.class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:09:26.567956Z","iopub.status.busy":"2023-06-06T14:09:26.567638Z","iopub.status.idle":"2023-06-06T14:09:26.573355Z","shell.execute_reply":"2023-06-06T14:09:26.572375Z","shell.execute_reply.started":"2023-06-06T14:09:26.567933Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# # See an example batch of data\n","# for images, labels in train_data_10_percent.take(1):\n","#   print(images, labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:09:26.578344Z","iopub.status.busy":"2023-06-06T14:09:26.578098Z","iopub.status.idle":"2023-06-06T14:10:07.814239Z","shell.execute_reply":"2023-06-06T14:10:07.813098Z","shell.execute_reply.started":"2023-06-06T14:09:26.578322Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# 1. Create base model with tf.keras.applications\n","base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n","\n","# 2. Freeze the base model (so the pre-learned patterns remain)\n","base_model.trainable = False\n","\n","# 3. Create inputs into the base model\n","inputs = tf.keras.layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n","\n","# 4. If using ResNet50V2, add this to speed up convergence, remove for EfficientNet\n","# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n","\n","# 5. Pass the inputs to the base_model (note: using tf.keras.applications, EfficientNet inputs don't have to be normalized)\n","x = base_model(inputs)\n","# Check data shape after passing it to base_model\n","print(f\"Shape after base_model: {x.shape}\")\n","\n","# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce number of computations)\n","x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n","print(f\"After GlobalAveragePooling2D(): {x.shape}\")\n","\n","# 7. Create the output activation layer\n","outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n","\n","# 8. Combine the inputs with the outputs into a model\n","model_0 = tf.keras.Model(inputs, outputs)\n","\n","# 9. Compile the model\n","model_0.compile(loss='categorical_crossentropy',\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=[\"accuracy\"])\n","\n","# 10. Fit the model (we use less steps for validation so it's faster)\n","history_10_percent = model_0.fit(train_data_10_percent,\n","                                 epochs=5,\n","                                 steps_per_epoch=len(train_data_10_percent),\n","                                 validation_data=test_data_10_percent,\n","                                 # Go through less of the validation data so epochs are faster (we want faster experiments!)\n","                                 validation_steps=int(0.25 * len(test_data_10_percent)), \n","                                 # Track our model's training logs for visualization later\n","                                 callbacks=[create_tensorboard_callback(\"transfer_learning\", \"10_percent_feature_extract\")])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:10:07.817924Z","iopub.status.busy":"2023-06-06T14:10:07.817623Z","iopub.status.idle":"2023-06-06T14:10:18.076394Z","shell.execute_reply":"2023-06-06T14:10:18.075416Z","shell.execute_reply.started":"2023-06-06T14:10:07.817898Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["model_0.evaluate(test_data_10_percent)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:10:18.078552Z","iopub.status.busy":"2023-06-06T14:10:18.078186Z","iopub.status.idle":"2023-06-06T14:10:18.087919Z","shell.execute_reply":"2023-06-06T14:10:18.086940Z","shell.execute_reply.started":"2023-06-06T14:10:18.078519Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Check layers in our base model\n","for layer_number, layer in enumerate(base_model.layers):\n","  print(layer_number, layer.name)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:10:18.090346Z","iopub.status.busy":"2023-06-06T14:10:18.089663Z","iopub.status.idle":"2023-06-06T14:10:18.548618Z","shell.execute_reply":"2023-06-06T14:10:18.547841Z","shell.execute_reply.started":"2023-06-06T14:10:18.090313Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["base_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:10:18.550295Z","iopub.status.busy":"2023-06-06T14:10:18.549731Z","iopub.status.idle":"2023-06-06T14:10:18.606545Z","shell.execute_reply":"2023-06-06T14:10:18.605774Z","shell.execute_reply.started":"2023-06-06T14:10:18.550255Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Check summary of model constructed with Functional API\n","model_0.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:10:18.607772Z","iopub.status.busy":"2023-06-06T14:10:18.607457Z","iopub.status.idle":"2023-06-06T14:10:19.669309Z","shell.execute_reply":"2023-06-06T14:10:19.668254Z","shell.execute_reply.started":"2023-06-06T14:10:18.607742Z"},"trusted":true},"outputs":[],"source":["# Check out our model's training curves\n","plot_loss_curves(history_10_percent)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:10:19.670791Z","iopub.status.busy":"2023-06-06T14:10:19.670497Z","iopub.status.idle":"2023-06-06T14:10:19.724697Z","shell.execute_reply":"2023-06-06T14:10:19.723663Z","shell.execute_reply.started":"2023-06-06T14:10:19.670767Z"},"trusted":true},"outputs":[],"source":["# Define input tensor shape (same number of dimensions as the output of efficientnetb0)\n","input_shape = (1, 4, 4, 3)\n","\n","# Create a random tensor\n","tf.random.set_seed(42)\n","input_tensor = tf.random.normal(input_shape)\n","print(f\"Random input tensor:\\n {input_tensor}\\n\")\n","\n","# Pass the random tensor through a global average pooling 2D layer\n","global_average_pooled_tensor = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n","print(f\"2D global average pooled random tensor:\\n {global_average_pooled_tensor}\\n\")\n","\n","# Check the shapes of the different tensors\n","print(f\"Shape of input tensor: {input_tensor.shape}\")\n","print(f\"Shape of 2D global averaged pooled input tensor: {global_average_pooled_tensor.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:10:19.726900Z","iopub.status.busy":"2023-06-06T14:10:19.726466Z","iopub.status.idle":"2023-06-06T14:10:19.735175Z","shell.execute_reply":"2023-06-06T14:10:19.734006Z","shell.execute_reply.started":"2023-06-06T14:10:19.726865Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# This is the same as GlobalAveragePooling2D()\n","tf.reduce_mean(input_tensor, axis=[1, 2]) # average across the middle axes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:10:19.737781Z","iopub.status.busy":"2023-06-06T14:10:19.736818Z","iopub.status.idle":"2023-06-06T14:10:22.597498Z","shell.execute_reply":"2023-06-06T14:10:22.596393Z","shell.execute_reply.started":"2023-06-06T14:10:19.737742Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Download and unzip data\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\n","unzip_data(\"10_food_classes_1_percent.zip\")\n","\n","# Create training and test dirs\n","train_dir_1_percent = \"10_food_classes_1_percent/train/\"\n","test_dir = \"10_food_classes_1_percent/test/\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:10:22.600140Z","iopub.status.busy":"2023-06-06T14:10:22.599572Z","iopub.status.idle":"2023-06-06T14:10:22.611106Z","shell.execute_reply":"2023-06-06T14:10:22.610114Z","shell.execute_reply.started":"2023-06-06T14:10:22.600102Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Walk through 1 percent data directory and list number of files\n","walk_through_dir(\"10_food_classes_1_percent\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:10:22.613405Z","iopub.status.busy":"2023-06-06T14:10:22.612821Z","iopub.status.idle":"2023-06-06T14:10:22.918554Z","shell.execute_reply":"2023-06-06T14:10:22.917646Z","shell.execute_reply.started":"2023-06-06T14:10:22.613375Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","IMG_SIZE = (224, 224)\n","train_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir_1_percent,\n","                                                                           label_mode=\"categorical\",\n","                                                                           batch_size=32, # default\n","                                                                           image_size=IMG_SIZE)\n","test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n","                                                                label_mode=\"categorical\",\n","                                                                image_size=IMG_SIZE)"]},{"cell_type":"markdown","metadata":{},"source":["Data loaded. Time to augment it."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:10:22.920324Z","iopub.status.busy":"2023-06-06T14:10:22.919897Z","iopub.status.idle":"2023-06-06T14:10:22.944972Z","shell.execute_reply":"2023-06-06T14:10:22.944130Z","shell.execute_reply.started":"2023-06-06T14:10:22.920290Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers.experimental import preprocessing\n","\n","# Create a data augmentation stage with horizontal flipping, rotations, zooms\n","data_augmentation = keras.Sequential([\n","  preprocessing.RandomFlip(\"horizontal\"),\n","  preprocessing.RandomRotation(0.2),\n","  preprocessing.RandomZoom(0.2),\n","  preprocessing.RandomHeight(0.2),\n","  preprocessing.RandomWidth(0.2),\n","  #preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetB0\n","], name =\"data_augmentation\")\n","\n","# resize_and_rescaling=keras.Sequential([\n","#     layers.resize(224,224),\n","#     layers.rescaling(1./255)\n","# ])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:10:22.946933Z","iopub.status.busy":"2023-06-06T14:10:22.946582Z","iopub.status.idle":"2023-06-06T14:10:23.949895Z","shell.execute_reply":"2023-06-06T14:10:23.948885Z","shell.execute_reply.started":"2023-06-06T14:10:22.946901Z"},"trusted":true},"outputs":[],"source":["# View a random image\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import os\n","import random\n","target_class = random.choice(train_data_1_percent.class_names) # choose a random class\n","target_dir = \"10_food_classes_1_percent/train/\" + target_class # create the target directory\n","random_image = random.choice(os.listdir(target_dir)) # choose a random image from target directory\n","random_image_path = target_dir + \"/\" + random_image # create the choosen random image path\n","img = mpimg.imread(random_image_path) # read in the chosen target image\n","plt.imshow(img) # plot the target image\n","plt.title(f\"Original random image from class: {target_class}\")\n","plt.axis(False); # turn off the axes\n","\n","# Augment the image\n","augmented_img = data_augmentation(tf.expand_dims(img, axis=0),training=True) # data augmentation model requires shape (None, height, width, 3)\n","plt.figure()\n","plt.imshow(tf.squeeze(augmented_img)/255.) # requires normalization after augmentation\n","plt.title(f\"Augmented random image from class: {target_class}\")\n","plt.axis(False);"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:10:23.952017Z","iopub.status.busy":"2023-06-06T14:10:23.951640Z","iopub.status.idle":"2023-06-06T14:11:02.606918Z","shell.execute_reply":"2023-06-06T14:11:02.605995Z","shell.execute_reply.started":"2023-06-06T14:10:23.951981Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Setup input shape and base model, freezing the base model layers\n","input_shape = (224, 224, 3)\n","base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n","base_model.trainable = False\n","\n","# Create input layer\n","inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n","\n","# Add in data augmentation Sequential model as a layer\n","x = data_augmentation(inputs)\n","\n","# Give base_model inputs (after augmentation) and don't train it\n","x = base_model(x, training=False)\n","\n","# Pool output features of base model\n","x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n","\n","# Put a dense layer on as the output\n","outputs = layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n","\n","# Make a model with inputs and outputs\n","model_1 = keras.Model(inputs, outputs)\n","\n","# Compile the model\n","model_1.compile(loss=\"categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=[\"accuracy\"])\n","\n","# Fit the model\n","history_1_percent = model_1.fit(train_data_1_percent,\n","                    epochs=5,\n","                    steps_per_epoch=len(train_data_1_percent),\n","                    validation_data=test_data,\n","                    validation_steps=int(0.25* len(test_data)), # validate for less steps\n","                    # Track model training logs\n","                    callbacks=[create_tensorboard_callback(\"transfer_learning\", \"1_percent_data_aug\")])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:11:02.609050Z","iopub.status.busy":"2023-06-06T14:11:02.608323Z","iopub.status.idle":"2023-06-06T14:11:02.650874Z","shell.execute_reply":"2023-06-06T14:11:02.649988Z","shell.execute_reply.started":"2023-06-06T14:11:02.609000Z"},"trusted":true},"outputs":[],"source":["# Check out model summary\n","model_1.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:11:02.654754Z","iopub.status.busy":"2023-06-06T14:11:02.654389Z","iopub.status.idle":"2023-06-06T14:11:07.843495Z","shell.execute_reply":"2023-06-06T14:11:07.842642Z","shell.execute_reply.started":"2023-06-06T14:11:02.654719Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Evaluate on the test data\n","results_1_percent_data_aug = model_1.evaluate(test_data)\n","results_1_percent_data_aug"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:11:07.845254Z","iopub.status.busy":"2023-06-06T14:11:07.844860Z","iopub.status.idle":"2023-06-06T14:11:08.556499Z","shell.execute_reply":"2023-06-06T14:11:08.555559Z","shell.execute_reply.started":"2023-06-06T14:11:07.845216Z"},"trusted":true},"outputs":[],"source":["# How does the model go with a data augmentation layer with 1% of data\n","plot_loss_curves(history_1_percent)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:11:08.558365Z","iopub.status.busy":"2023-06-06T14:11:08.558012Z","iopub.status.idle":"2023-06-06T14:11:08.563112Z","shell.execute_reply":"2023-06-06T14:11:08.562154Z","shell.execute_reply.started":"2023-06-06T14:11:08.558332Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Get 10% of the data of the 10 classes (uncomment if you haven't gotten \"10_food_classes_10_percent.zip\" already)\n","# !wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","# unzip_data(\"10_food_classes_10_percent.zip\")\n","\n","train_dir_10_percent = \"10_food_classes_10_percent/train/\"\n","test_dir = \"10_food_classes_10_percent/test/\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:11:08.571829Z","iopub.status.busy":"2023-06-06T14:11:08.571505Z","iopub.status.idle":"2023-06-06T14:11:08.934688Z","shell.execute_reply":"2023-06-06T14:11:08.933773Z","shell.execute_reply.started":"2023-06-06T14:11:08.571802Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Setup data inputs\n","import tensorflow as tf\n","IMG_SIZE = (224, 224)\n","train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir_10_percent,\n","                                                                            label_mode=\"categorical\",\n","                                                                            image_size=IMG_SIZE)\n","# Note: the test data is the same as the previous experiment, we could\n","# skip creating this, but we'll leave this here to practice.\n","test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n","                                                                label_mode=\"categorical\",\n","                                                                image_size=IMG_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:11:08.937035Z","iopub.status.busy":"2023-06-06T14:11:08.936688Z","iopub.status.idle":"2023-06-06T14:11:12.556832Z","shell.execute_reply":"2023-06-06T14:11:12.555895Z","shell.execute_reply.started":"2023-06-06T14:11:08.937002Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Create a functional model with data augmentation\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers.experimental import preprocessing\n","from tensorflow.keras.models import Sequential\n","\n","# Build data augmentation layer\n","data_augmentation = Sequential([\n","  preprocessing.RandomFlip('horizontal'),\n","  preprocessing.RandomHeight(0.2),\n","  preprocessing.RandomWidth(0.2),\n","  preprocessing.RandomZoom(0.2),\n","  preprocessing.RandomRotation(0.2),\n","  # preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNet                 \n","], name=\"data_augmentation\")\n","\n","# Setup the input shape to our model\n","input_shape = (224, 224, 3)\n","\n","# Create a frozen base model\n","base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n","base_model.trainable = False\n","\n","# Create input and output layers\n","inputs = layers.Input(shape=input_shape, name=\"input_layer\") # create input layer\n","x = data_augmentation(inputs) # augment our training images\n","x = base_model(x, training=False) # pass augmented images to base model but keep it in inference mode, so batchnorm layers don't get updated: https://keras.io/guides/transfer_learning/#build-a-model \n","x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n","outputs = layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n","model_2 = tf.keras.Model(inputs, outputs)\n","\n","# Compile\n","model_2.compile(loss=\"categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.Adam(lr=0.001), # use Adam optimizer with base learning rate\n","              metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:11:12.558619Z","iopub.status.busy":"2023-06-06T14:11:12.558265Z","iopub.status.idle":"2023-06-06T14:11:12.600013Z","shell.execute_reply":"2023-06-06T14:11:12.599040Z","shell.execute_reply.started":"2023-06-06T14:11:12.558570Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["model_2.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:11:12.602018Z","iopub.status.busy":"2023-06-06T14:11:12.601440Z","iopub.status.idle":"2023-06-06T14:11:12.607256Z","shell.execute_reply":"2023-06-06T14:11:12.606351Z","shell.execute_reply.started":"2023-06-06T14:11:12.601985Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Setup checkpoint path\n","checkpoint_path = \"ten_percent_model_checkpoints_weights/checkpoint.ckpt\" # note: remember saving directly to Colab is temporary\n","\n","# Create a ModelCheckpoint callback that saves the model's weights only\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                         save_weights_only=True, # set to False to save the entire model\n","                                                         save_best_only=False, # set to True to save only the best model instead of a model every epoch \n","                                                         save_freq=\"epoch\", # save every epoch\n","                                                         verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:11:12.609166Z","iopub.status.busy":"2023-06-06T14:11:12.608611Z","iopub.status.idle":"2023-06-06T14:12:16.793268Z","shell.execute_reply":"2023-06-06T14:12:16.792191Z","shell.execute_reply.started":"2023-06-06T14:11:12.609135Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Fit the model saving checkpoints every epoch\n","initial_epochs = 5\n","history_10_percent_data_aug = model_2.fit(train_data_10_percent,\n","                                          epochs=initial_epochs,\n","                                          validation_data=test_data,\n","                                          validation_steps=int(0.25 * len(test_data)), # do less steps per validation (quicker)\n","                                          callbacks=[create_tensorboard_callback(\"transfer_learning\", \"10_percent_data_aug\"), \n","                                                     checkpoint_callback])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:16.795589Z","iopub.status.busy":"2023-06-06T14:12:16.795169Z","iopub.status.idle":"2023-06-06T14:12:27.042916Z","shell.execute_reply":"2023-06-06T14:12:27.041837Z","shell.execute_reply.started":"2023-06-06T14:12:16.795548Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Evaluate on the test data\n","results_10_percent_data_aug = model_2.evaluate(test_data)\n","results_10_percent_data_aug"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:27.045164Z","iopub.status.busy":"2023-06-06T14:12:27.044796Z","iopub.status.idle":"2023-06-06T14:12:27.742334Z","shell.execute_reply":"2023-06-06T14:12:27.741283Z","shell.execute_reply.started":"2023-06-06T14:12:27.045130Z"},"trusted":true},"outputs":[],"source":["# Plot model loss curves\n","plot_loss_curves(history_10_percent_data_aug)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:27.744165Z","iopub.status.busy":"2023-06-06T14:12:27.743729Z","iopub.status.idle":"2023-06-06T14:12:39.378907Z","shell.execute_reply":"2023-06-06T14:12:39.377904Z","shell.execute_reply.started":"2023-06-06T14:12:27.744131Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Load in saved model weights and evaluate model\n","model_2.load_weights(checkpoint_path)\n","loaded_weights_model_results = model_2.evaluate(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:39.380466Z","iopub.status.busy":"2023-06-06T14:12:39.380181Z","iopub.status.idle":"2023-06-06T14:12:39.387903Z","shell.execute_reply":"2023-06-06T14:12:39.386786Z","shell.execute_reply.started":"2023-06-06T14:12:39.380442Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# If the results from our native model and the loaded weights are the same, this should output True\n","results_10_percent_data_aug == loaded_weights_model_results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:39.390247Z","iopub.status.busy":"2023-06-06T14:12:39.389446Z","iopub.status.idle":"2023-06-06T14:12:39.400914Z","shell.execute_reply":"2023-06-06T14:12:39.399978Z","shell.execute_reply.started":"2023-06-06T14:12:39.390214Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["import numpy as np\n","# Check to see if loaded model results are very close to native model results (should output True)\n","np.isclose(np.array(results_10_percent_data_aug), np.array(loaded_weights_model_results))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:39.402900Z","iopub.status.busy":"2023-06-06T14:12:39.402316Z","iopub.status.idle":"2023-06-06T14:12:39.414759Z","shell.execute_reply":"2023-06-06T14:12:39.413574Z","shell.execute_reply.started":"2023-06-06T14:12:39.402873Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Check the difference between the two results\n","print(np.array(results_10_percent_data_aug) - np.array(loaded_weights_model_results))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:39.417112Z","iopub.status.busy":"2023-06-06T14:12:39.416627Z","iopub.status.idle":"2023-06-06T14:12:39.427843Z","shell.execute_reply":"2023-06-06T14:12:39.426548Z","shell.execute_reply.started":"2023-06-06T14:12:39.417074Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Layers in loaded model\n","model_2.layers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:39.429892Z","iopub.status.busy":"2023-06-06T14:12:39.429425Z","iopub.status.idle":"2023-06-06T14:12:39.437680Z","shell.execute_reply":"2023-06-06T14:12:39.436002Z","shell.execute_reply.started":"2023-06-06T14:12:39.429861Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["for layer in model_2.layers:\n","  print(layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:39.440280Z","iopub.status.busy":"2023-06-06T14:12:39.439206Z","iopub.status.idle":"2023-06-06T14:12:39.485636Z","shell.execute_reply":"2023-06-06T14:12:39.484756Z","shell.execute_reply.started":"2023-06-06T14:12:39.440233Z"},"trusted":true},"outputs":[],"source":["model_2.summary()"]},{"cell_type":"markdown","metadata":{},"source":["Alright, it looks like all of the layers in the `efficientnetb0` layer are frozen. We can confirm this using the `trainable_variables` attribute."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:39.487641Z","iopub.status.busy":"2023-06-06T14:12:39.487001Z","iopub.status.idle":"2023-06-06T14:12:39.492845Z","shell.execute_reply":"2023-06-06T14:12:39.491890Z","shell.execute_reply.started":"2023-06-06T14:12:39.487605Z"},"trusted":true},"outputs":[],"source":["# How many layers are trainable in our base model?\n","print(len(model_2.layers[2].trainable_variables)) # layer at index 2 is the EfficientNetB0 layer (the base model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:39.495128Z","iopub.status.busy":"2023-06-06T14:12:39.494483Z","iopub.status.idle":"2023-06-06T14:12:39.503411Z","shell.execute_reply":"2023-06-06T14:12:39.502326Z","shell.execute_reply.started":"2023-06-06T14:12:39.495093Z"},"trusted":true},"outputs":[],"source":["print(len(base_model.trainable_variables))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:39.505576Z","iopub.status.busy":"2023-06-06T14:12:39.504865Z","iopub.status.idle":"2023-06-06T14:12:39.518805Z","shell.execute_reply":"2023-06-06T14:12:39.517765Z","shell.execute_reply.started":"2023-06-06T14:12:39.505534Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Check which layers are tuneable (trainable)\n","for layer_number, layer in enumerate(base_model.layers):\n","  print(layer_number, layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:39.521085Z","iopub.status.busy":"2023-06-06T14:12:39.520438Z","iopub.status.idle":"2023-06-06T14:12:39.556185Z","shell.execute_reply":"2023-06-06T14:12:39.555371Z","shell.execute_reply.started":"2023-06-06T14:12:39.521053Z"},"trusted":true},"outputs":[],"source":["base_model.trainable = True\n","\n","# Freeze all layers except for the last 10\n","for layer in base_model.layers[:-10]:\n","  layer.trainable = False\n","\n","# Recompile the model (always recompile after any adjustments to a model)\n","model_2.compile(loss=\"categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr is 10x lower than before for fine-tuning IMPORTANT TO AVOID OVERTRAINING\n","              metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:39.559010Z","iopub.status.busy":"2023-06-06T14:12:39.558454Z","iopub.status.idle":"2023-06-06T14:12:39.569355Z","shell.execute_reply":"2023-06-06T14:12:39.568300Z","shell.execute_reply.started":"2023-06-06T14:12:39.558978Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Check which layers are tuneable (trainable)\n","for layer_number, layer in enumerate(base_model.layers):\n","  print(layer_number, layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:39.571522Z","iopub.status.busy":"2023-06-06T14:12:39.571028Z","iopub.status.idle":"2023-06-06T14:12:39.580748Z","shell.execute_reply":"2023-06-06T14:12:39.579624Z","shell.execute_reply.started":"2023-06-06T14:12:39.571491Z"},"trusted":true},"outputs":[],"source":["print(len(model_2.trainable_variables))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:12:39.582578Z","iopub.status.busy":"2023-06-06T14:12:39.582208Z","iopub.status.idle":"2023-06-06T14:13:51.857711Z","shell.execute_reply":"2023-06-06T14:13:51.856704Z","shell.execute_reply.started":"2023-06-06T14:12:39.582539Z"},"trusted":true},"outputs":[],"source":["# Fine tune for another 5 epochs\n","fine_tune_epochs = initial_epochs + 5\n","\n","# Refit the model (same as model_2 except with more trainable layers)\n","history_fine_10_percent_data_aug = model_2.fit(train_data_10_percent,\n","                                               epochs=fine_tune_epochs,\n","                                               validation_data=test_data,\n","                                               initial_epoch=history_10_percent_data_aug.epoch[-1], # start from previous last epoch\n","                                               validation_steps=int(0.25 * len(test_data)),\n","                                               callbacks=[create_tensorboard_callback(\"transfer_learning\", \"10_percent_fine_tune_last_10\")]) # name experiment appropriately"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:13:51.859993Z","iopub.status.busy":"2023-06-06T14:13:51.859589Z","iopub.status.idle":"2023-06-06T14:13:57.042779Z","shell.execute_reply":"2023-06-06T14:13:57.041754Z","shell.execute_reply.started":"2023-06-06T14:13:51.859958Z"},"trusted":true},"outputs":[],"source":["# Evaluate the model on the test data\n","results_fine_tune_10_percent = model_2.evaluate(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:13:57.049656Z","iopub.status.busy":"2023-06-06T14:13:57.047370Z","iopub.status.idle":"2023-06-06T14:13:57.070133Z","shell.execute_reply":"2023-06-06T14:13:57.068807Z","shell.execute_reply.started":"2023-06-06T14:13:57.049618Z"},"trusted":true},"outputs":[],"source":["def compare_historys(original_history, new_history, initial_epochs=5):\n","    \"\"\"\n","    Compares two model history objects.\n","    \"\"\"\n","    # Get original history measurements\n","    acc = original_history.history[\"accuracy\"]\n","    loss = original_history.history[\"loss\"]\n","\n","    print(len(acc))\n","\n","    val_acc = original_history.history[\"val_accuracy\"]\n","    val_loss = original_history.history[\"val_loss\"]\n","\n","    # Combine original history with new history\n","    total_acc = acc + new_history.history[\"accuracy\"]\n","    total_loss = loss + new_history.history[\"loss\"]\n","\n","    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n","    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n","\n","    print(len(total_acc))\n","    print(total_acc)\n","\n","    # Make plots\n","    plt.figure(figsize=(8, 8))\n","    plt.subplot(2, 1, 1)\n","    plt.plot(total_acc, label='Training Accuracy')\n","    plt.plot(total_val_acc, label='Validation Accuracy')\n","    plt.plot([initial_epochs-1, initial_epochs-1],\n","              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n","    plt.legend(loc='lower right')\n","    plt.title('Training and Validation Accuracy')\n","\n","    plt.subplot(2, 1, 2)\n","    plt.plot(total_loss, label='Training Loss')\n","    plt.plot(total_val_loss, label='Validation Loss')\n","    plt.plot([initial_epochs-1, initial_epochs-1],\n","              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n","    plt.legend(loc='upper right')\n","    plt.title('Training and Validation Loss')\n","    plt.xlabel('epoch')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:13:57.078937Z","iopub.status.busy":"2023-06-06T14:13:57.078054Z","iopub.status.idle":"2023-06-06T14:13:57.615520Z","shell.execute_reply":"2023-06-06T14:13:57.614573Z","shell.execute_reply.started":"2023-06-06T14:13:57.078744Z"},"trusted":true},"outputs":[],"source":["compare_historys(original_history=history_10_percent_data_aug, \n","                 new_history=history_fine_10_percent_data_aug, \n","                 initial_epochs=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:13:57.617508Z","iopub.status.busy":"2023-06-06T14:13:57.617076Z","iopub.status.idle":"2023-06-06T14:14:05.615389Z","shell.execute_reply":"2023-06-06T14:14:05.614082Z","shell.execute_reply.started":"2023-06-06T14:13:57.617474Z"},"trusted":true},"outputs":[],"source":["# Download and unzip 10 classes of data with all images\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip \n","unzip_data(\"10_food_classes_all_data.zip\")\n","\n","# Setup data directories\n","train_dir = \"10_food_classes_all_data/train/\"\n","test_dir = \"10_food_classes_all_data/test/\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:14:05.617881Z","iopub.status.busy":"2023-06-06T14:14:05.617459Z","iopub.status.idle":"2023-06-06T14:14:05.638639Z","shell.execute_reply":"2023-06-06T14:14:05.637657Z","shell.execute_reply.started":"2023-06-06T14:14:05.617843Z"},"trusted":true},"outputs":[],"source":["# How many images are we working with now?\n","walk_through_dir(\"10_food_classes_all_data\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:14:05.640576Z","iopub.status.busy":"2023-06-06T14:14:05.640157Z","iopub.status.idle":"2023-06-06T14:14:06.556192Z","shell.execute_reply":"2023-06-06T14:14:06.555291Z","shell.execute_reply.started":"2023-06-06T14:14:05.640544Z"},"trusted":true},"outputs":[],"source":["# Setup data inputs\n","import tensorflow as tf\n","IMG_SIZE = (224, 224)\n","train_data_10_classes_full = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n","                                                                                 label_mode=\"categorical\",\n","                                                                                 image_size=IMG_SIZE)\n","\n","# Note: this is the same test dataset we've been using for the previous modelling experiments\n","test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n","                                                                label_mode=\"categorical\",\n","                                                                image_size=IMG_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:14:06.558317Z","iopub.status.busy":"2023-06-06T14:14:06.557990Z","iopub.status.idle":"2023-06-06T14:14:12.589477Z","shell.execute_reply":"2023-06-06T14:14:12.588615Z","shell.execute_reply.started":"2023-06-06T14:14:06.558286Z"},"trusted":true},"outputs":[],"source":["# Evaluate model (this is the fine-tuned 10 percent of data version)\n","model_2.evaluate(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:14:12.592685Z","iopub.status.busy":"2023-06-06T14:14:12.592383Z","iopub.status.idle":"2023-06-06T14:14:12.599628Z","shell.execute_reply":"2023-06-06T14:14:12.598770Z","shell.execute_reply.started":"2023-06-06T14:14:12.592660Z"},"trusted":true},"outputs":[],"source":["results_fine_tune_10_percent"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:16:15.599729Z","iopub.status.busy":"2023-06-06T14:16:15.598762Z","iopub.status.idle":"2023-06-06T14:16:15.604660Z","shell.execute_reply":"2023-06-06T14:16:15.603481Z","shell.execute_reply.started":"2023-06-06T14:16:15.599696Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","print(f\"TensorFlow version: {tf.__version__}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:16:46.880672Z","iopub.status.busy":"2023-06-06T14:16:46.879694Z","iopub.status.idle":"2023-06-06T14:16:48.153573Z","shell.execute_reply":"2023-06-06T14:16:48.152268Z","shell.execute_reply.started":"2023-06-06T14:16:46.880621Z"},"trusted":true},"outputs":[],"source":["# Load model from checkpoint, that way we can fine-tune from the same stage the 10 percent data model was fine-tuned from\n","checkpoint_dir = \"ten_percent_model_checkpoints_weights\"\n","latest_weights = tf.train.latest_checkpoint(checkpoint_dir)\n","\n","# Note: As of TensorFlow 2.10.0+, this may error, it should work with TensorFlow 2.9.0\n","# See the fix here: https://github.com/mrdbourke/tensorflow-deep-learning/issues/544\n","# Load model from checkpoint, that way we can fine-tune from the same stage the 10 percent data model was fine-tuned from\n","model_2.load_weights(checkpoint_path) # revert model back to saved weights"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:17:37.062789Z","iopub.status.busy":"2023-06-06T14:17:37.062135Z","iopub.status.idle":"2023-06-06T14:17:43.744622Z","shell.execute_reply":"2023-06-06T14:17:43.743611Z","shell.execute_reply.started":"2023-06-06T14:17:37.062743Z"},"trusted":true},"outputs":[],"source":["# After loading the weights, this should have gone down (no fine-tuning)\n","model_2.evaluate(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:17:43.748855Z","iopub.status.busy":"2023-06-06T14:17:43.746401Z","iopub.status.idle":"2023-06-06T14:17:43.755697Z","shell.execute_reply":"2023-06-06T14:17:43.754667Z","shell.execute_reply.started":"2023-06-06T14:17:43.748819Z"},"trusted":true},"outputs":[],"source":["# Check to see if the above two results are the same (they should be)\n","results_10_percent_data_aug"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:17:59.207028Z","iopub.status.busy":"2023-06-06T14:17:59.206509Z","iopub.status.idle":"2023-06-06T14:17:59.216201Z","shell.execute_reply":"2023-06-06T14:17:59.213620Z","shell.execute_reply.started":"2023-06-06T14:17:59.206992Z"},"trusted":true},"outputs":[],"source":["# Check which layers are tuneable in the whole model\n","for layer_number, layer in enumerate(model_2.layers):\n","  print(layer_number, layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:18:13.759401Z","iopub.status.busy":"2023-06-06T14:18:13.759030Z","iopub.status.idle":"2023-06-06T14:18:13.770673Z","shell.execute_reply":"2023-06-06T14:18:13.768794Z","shell.execute_reply.started":"2023-06-06T14:18:13.759370Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Check which layers are tuneable in the base model\n","for layer_number, layer in enumerate(base_model.layers):\n","  print(layer_number, layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:18:36.733436Z","iopub.status.busy":"2023-06-06T14:18:36.732551Z","iopub.status.idle":"2023-06-06T14:18:36.752379Z","shell.execute_reply":"2023-06-06T14:18:36.751429Z","shell.execute_reply.started":"2023-06-06T14:18:36.733392Z"},"trusted":true},"outputs":[],"source":["# Compile\n","model_2.compile(loss=\"categorical_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(lr=0.0001), # divide learning rate by 10 for fine-tuning\n","                metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:18:41.767814Z","iopub.status.busy":"2023-06-06T14:18:41.767392Z","iopub.status.idle":"2023-06-06T14:22:32.081987Z","shell.execute_reply":"2023-06-06T14:22:32.080882Z","shell.execute_reply.started":"2023-06-06T14:18:41.767779Z"},"trusted":true},"outputs":[],"source":["# Continue to train and fine-tune the model to our data\n","fine_tune_epochs = initial_epochs + 5\n","\n","history_fine_10_classes_full = model_2.fit(train_data_10_classes_full,\n","                                           epochs=fine_tune_epochs,\n","                                           initial_epoch=history_10_percent_data_aug.epoch[-1],\n","                                           validation_data=test_data,\n","                                           validation_steps=int(0.25 * len(test_data)),\n","                                           callbacks=[create_tensorboard_callback(\"transfer_learning\", \"full_10_classes_fine_tune_last_10\")])"]},{"cell_type":"markdown","metadata":{},"source":["> ðŸ”‘ **Note:** Training took longer per epoch, but that makes sense because we're using 10x more training data than before.\n","\n","Let's evaluate on all of the test data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:22:32.367703Z","iopub.status.busy":"2023-06-06T14:22:32.367255Z","iopub.status.idle":"2023-06-06T14:22:42.619623Z","shell.execute_reply":"2023-06-06T14:22:42.618443Z","shell.execute_reply.started":"2023-06-06T14:22:32.367642Z"},"trusted":true},"outputs":[],"source":["results_fine_tune_full_data = model_2.evaluate(test_data)\n","results_fine_tune_full_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:22:42.621585Z","iopub.status.busy":"2023-06-06T14:22:42.621143Z","iopub.status.idle":"2023-06-06T14:22:43.195447Z","shell.execute_reply":"2023-06-06T14:22:43.194518Z","shell.execute_reply.started":"2023-06-06T14:22:42.621551Z"},"trusted":true},"outputs":[],"source":["compare_historys(original_history=history_10_percent_data_aug,\n","                 new_history=history_fine_10_classes_full,\n","                 initial_epochs=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:23:38.898151Z","iopub.status.busy":"2023-06-06T14:23:38.897684Z","iopub.status.idle":"2023-06-06T14:23:38.903504Z","shell.execute_reply":"2023-06-06T14:23:38.902321Z","shell.execute_reply.started":"2023-06-06T14:23:38.898113Z"},"trusted":true},"outputs":[],"source":["# # View tensorboard logs of transfer learning modelling experiments (should be 4 models)\n","# # Upload TensorBoard dev records\n","# !tensorboard dev upload --logdir ./transfer_learning \\\n","#   --name \"Transfer learning experiments\" \\\n","#   --description \"A series of different transfer learning experiments with varying amounts of data and fine-tuning\" \\\n","#   --one_shot # exits the uploader when upload has finished"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-06T14:23:54.143665Z","iopub.status.busy":"2023-06-06T14:23:54.143051Z","iopub.status.idle":"2023-06-06T14:23:54.148192Z","shell.execute_reply":"2023-06-06T14:23:54.147108Z","shell.execute_reply.started":"2023-06-06T14:23:54.143620Z"},"trusted":true},"outputs":[],"source":["# Remove previous experiments\n","# !tensorboard dev delete --experiment_id ..."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
